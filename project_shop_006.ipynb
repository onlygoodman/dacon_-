{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project_shop_006",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "18ablmK7JuK31KsG6RXAdH3sj-4mOhHdj",
      "authorship_tag": "ABX9TyP7FqdXyScUsIkivWN5euuf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/onlygoodman/dacon_shopping_reviewscore_predict/blob/main/project_shop_006.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "001 - https://wikidocs.net/94600 네이버 쇼핑 리뷰 데이터 분석을 참조하여 0,1 긍부정 이진 분류를 통해 확률을 0~5로 확장하여 예측\n",
        "\n",
        "\n",
        "002 - 001 코드에서 target 그대로 활용, 다중분류로 예측 시도\n",
        "\n",
        "003 - 002 코드에 dense layer 64, 32, 16, 8 사이에 각각 dropdout 0.2~0.5 적용하여 추가학습 epoch 25로 변경 early stop 인내값 8로 변경\n",
        "\n",
        "004 - 003에서 epoch, batch-size 등 hyper parameter search에 유의미한 결과를 얻지 못하여 hyperband를 활용하여 하이퍼파라미터 튜닝 시도\n",
        "\n",
        "005 - 004에서 얻은 하이퍼파라미터 튜닝 결과 대입하여 val_acc 측정 시도\n",
        "\n",
        "006 - 005모델의 결과를 개선하기 위해 우선 for 문으로 hidden, dense layer, batch size 하이퍼파라미터 튜닝 시도 256 32 16 값 도출 후 결과 제출시도\n",
        "\n"
      ],
      "metadata": {
        "id": "OqNcJqF5C4Fd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab에 Mecab 설치\n",
        "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n",
        "%cd Mecab-ko-for-Google-Colab\n",
        "!bash install_mecab-ko_on_colab190912.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwc4_a0FDMjm",
        "outputId": "ac1739ce-5a00-408c-c7c8-a6ace54d5ac6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Mecab-ko-for-Google-Colab'...\n",
            "remote: Enumerating objects: 115, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 115 (delta 11), reused 10 (delta 3), pack-reused 91\u001b[K\n",
            "Receiving objects: 100% (115/115), 1.27 MiB | 30.97 MiB/s, done.\n",
            "Resolving deltas: 100% (50/50), done.\n",
            "/content/Mecab-ko-for-Google-Colab\n",
            "Installing konlpy.....\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.4.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (453 kB)\n",
            "\u001b[K     |████████████████████████████████| 453 kB 58.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.1.1)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.4.0 konlpy-0.6.0\n",
            "Done\n",
            "Installing mecab-0.996-ko-0.9.2.tar.gz.....\n",
            "Downloading mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "--2022-07-15 06:53:51--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::22e9:9f55, 2406:da00:ff00::3403:4be7, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNCXEVYSBH&Signature=DCHtt0G5VFI763tlpvq4hPh0YNo%3D&x-amz-security-token=FwoGZXIvYXdzEHgaDHcmahXvPrQYkcDi7yK%2BAXDaEj4f7gZieanZheuwLQmqZwiur8rDTk%2FjTeEyCgcm2hY1O99xpAt6LbqW06xsvDZDzbpq2acIkQdATWT2Kq%2BHGiSjoXmG7yN4yRO8uxpvxts56ozTWnpBR9ugVVCb1836IlkquWfHfYE%2BYI5h%2BxcLZ8fWj6WrihUfceTji701gLLf7dcKwL23Hpyl5OJr4hDofUV%2FkBJynHvEoE2gWk2syquyaU4Bes4AEBDlMGc1vbH5A9gIldmrbcW2jjco%2F5vElgYyLXyHCTKKNdKBEvOAz4n4flpAwDWGoF2iKsyMnqceMUxEFfAXRLm6BojeGU5krg%3D%3D&Expires=1657869575 [following]\n",
            "--2022-07-15 06:53:51--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNCXEVYSBH&Signature=DCHtt0G5VFI763tlpvq4hPh0YNo%3D&x-amz-security-token=FwoGZXIvYXdzEHgaDHcmahXvPrQYkcDi7yK%2BAXDaEj4f7gZieanZheuwLQmqZwiur8rDTk%2FjTeEyCgcm2hY1O99xpAt6LbqW06xsvDZDzbpq2acIkQdATWT2Kq%2BHGiSjoXmG7yN4yRO8uxpvxts56ozTWnpBR9ugVVCb1836IlkquWfHfYE%2BYI5h%2BxcLZ8fWj6WrihUfceTji701gLLf7dcKwL23Hpyl5OJr4hDofUV%2FkBJynHvEoE2gWk2syquyaU4Bes4AEBDlMGc1vbH5A9gIldmrbcW2jjco%2F5vElgYyLXyHCTKKNdKBEvOAz4n4flpAwDWGoF2iKsyMnqceMUxEFfAXRLm6BojeGU5krg%3D%3D&Expires=1657869575\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 54.231.232.153\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|54.231.232.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1414979 (1.3M) [application/x-tar]\n",
            "Saving to: ‘mecab-0.996-ko-0.9.2.tar.gz’\n",
            "\n",
            "mecab-0.996-ko-0.9. 100%[===================>]   1.35M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2022-07-15 06:53:52 (34.5 MB/s) - ‘mecab-0.996-ko-0.9.2.tar.gz’ saved [1414979/1414979]\n",
            "\n",
            "Done\n",
            "Unpacking mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-0.996-ko-0.9.2.......\n",
            "installing mecab-0.996-ko-0.9.2.tar.gz........\n",
            "configure\n",
            "make\n",
            "make check\n",
            "make install\n",
            "ldconfig\n",
            "Done\n",
            "Change Directory to /content\n",
            "Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "--2022-07-15 06:55:06--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::22c0:3470, 2406:da00:ff00::22c5:2ef4, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNNS4BFHN2&Signature=VBAHw5pXWfUNeMClLo8r%2BtoH66I%3D&x-amz-security-token=FwoGZXIvYXdzEHgaDCBcDg9Ce1N3Du6VcCK%2BAdA%2FbdUlAeLrbifxC1cg%2FV8h8LddSFxnhV4MPST3xJf2Wqx8j38diPV4FiX2H5j7myzLOvF%2BuqVqPJxUqeXDUVamb8EFcNTvTB2TkckcGkX0hag4w4PNEHYbz91WLf7lstWtA%2FeGMyCTqZUrJVzFpCS8%2FTtEbsoTD8vHSnPXtSUNRTWLNgRHZq2IMz7Ovc0ZITEK3OzZk%2BehMMQHvLc9T2QpfnCYPeVRIQnXrcDD%2BbxI%2BtOVrRWeAiG8gHPmJjAosp7ElgYyLRyp40fnkZLxufzcMbsKXY2eQ4qivPB0SKtq0hkneO8%2BBfnUVdS4Ygw4GVq93A%3D%3D&Expires=1657869882 [following]\n",
            "--2022-07-15 06:55:06--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNNS4BFHN2&Signature=VBAHw5pXWfUNeMClLo8r%2BtoH66I%3D&x-amz-security-token=FwoGZXIvYXdzEHgaDCBcDg9Ce1N3Du6VcCK%2BAdA%2FbdUlAeLrbifxC1cg%2FV8h8LddSFxnhV4MPST3xJf2Wqx8j38diPV4FiX2H5j7myzLOvF%2BuqVqPJxUqeXDUVamb8EFcNTvTB2TkckcGkX0hag4w4PNEHYbz91WLf7lstWtA%2FeGMyCTqZUrJVzFpCS8%2FTtEbsoTD8vHSnPXtSUNRTWLNgRHZq2IMz7Ovc0ZITEK3OzZk%2BehMMQHvLc9T2QpfnCYPeVRIQnXrcDD%2BbxI%2BtOVrRWeAiG8gHPmJjAosp7ElgYyLRyp40fnkZLxufzcMbsKXY2eQ4qivPB0SKtq0hkneO8%2BBfnUVdS4Ygw4GVq93A%3D%3D&Expires=1657869882\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.217.231.65\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.217.231.65|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49775061 (47M) [application/x-tar]\n",
            "Saving to: ‘mecab-ko-dic-2.1.1-20180720.tar.gz’\n",
            "\n",
            "mecab-ko-dic-2.1.1- 100%[===================>]  47.47M   104MB/s    in 0.5s    \n",
            "\n",
            "2022-07-15 06:55:07 (104 MB/s) - ‘mecab-ko-dic-2.1.1-20180720.tar.gz’ saved [49775061/49775061]\n",
            "\n",
            "Done\n",
            "Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-ko-dic-2.1.1-20180720\n",
            "Done\n",
            "installing........\n",
            "configure\n",
            "make\n",
            "make install\n",
            "apt-get update\n",
            "apt-get upgrade\n",
            "apt install curl\n",
            "apt install git\n",
            "bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n",
            "Done\n",
            "Successfully Installed\n",
            "Now you can use Mecab\n",
            "from konlpy.tag import Mecab\n",
            "mecab = Mecab()\n",
            "사용자 사전 추가 방법 : https://bit.ly/3k0ZH53\n",
            "NameError: name 'Tagger' is not defined 오류 발생 시 런타임을 재실행 해주세요\n",
            "블로그에 해결 방법을 남겨주신 tana님 감사합니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib.request\n",
        "from collections import Counter\n",
        "from konlpy.tag import Mecab\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "ikNAjambDQBA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train dataset은 Label이 존재하지 않음\n",
        "train_data = pd.read_csv(\"/content/drive/MyDrive/shopping_dataset/train.csv\")\n",
        "test_data = pd.read_csv(\"/content/drive/MyDrive/shopping_dataset/test.csv\")\n",
        "submit = pd.read_csv(\"/content/drive/MyDrive/shopping_dataset/sample_submission.csv\")"
      ],
      "metadata": {
        "id": "2YoczkpNp9-b"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.head(10)\n",
        "train_data['target'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQW_zB_oqN9O",
        "outputId": "afa316cc-a6fd-4bde-8016-c906a9eef1aa"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 1, 5, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predata(data):\n",
        "  data['label'] = np.select([data.target > 3], [1], default = 0)\n",
        "\n",
        "  #혹시 중복이 있다면 제거\n",
        "  data.drop_duplicates(subset=['reviews'], inplace=True)"
      ],
      "metadata": {
        "id": "jZwx5B-cDkOM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predata(train_data)"
      ],
      "metadata": {
        "id": "2pZfdNh8EWuG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data['target'].value_counts().plot(kind='bar')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "kdV9EGzdE2hB",
        "outputId": "d2333f72-e3ba-42ce-8937-6b8024787d13"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ff534f53810>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.groupby('target').size().reset_index(name = 'count'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhERQCKmF0hl",
        "outputId": "0a98d35e-e3b7-4c90-dd44-d29a6d0d511a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   target  count\n",
            "0       1   4499\n",
            "1       2   8000\n",
            "2       4   2500\n",
            "3       5  10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 한글과 공백을 제외하고 모두 제거\n",
        "train_data['reviews'] = train_data['reviews'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
        "train_data['reviews'].replace('', np.nan, inplace=True)\n",
        "print(train_data.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrJRPOWWGAvk",
        "outputId": "5df52431-e3ae-47ad-e58d-4774f405a08d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id         0\n",
            "reviews    0\n",
            "target     0\n",
            "label      0\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test_data.drop_duplicates(subset = ['reviews'], inplace=True) # 중복 제거\n",
        "# test_data['reviews'] = test_data['reviews'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\") # 정규 표현식 수행\n",
        "# test_data['reviews'].replace('', np.nan, inplace=True) # 공백은 Null 값으로 변경\n",
        "# test_data = test_data.dropna(how='any') # Null 값 제거\n",
        "# print('전처리 후 테스트용 샘플의 개수 :',len(test_data))"
      ],
      "metadata": {
        "id": "2h1Xi-6_GI_7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = ['도', '는', '다', '의', '가', '이', '은', '한', '에', '하', '고', '을', '를', '인',\n",
        "             '듯', '과', '와', '네', '들', '듯', '지', '임', '게', '어', '거', '기', '했', '습니다']\n",
        "mecab = Mecab()\n",
        "\n",
        "train_data['tokenized'] = train_data['reviews'].apply(mecab.morphs)\n",
        "train_data['tokenized'] = train_data['tokenized'].apply(lambda x: [item for item in x if item not in stopwords])\n",
        "\n",
        "# test_data['tokenized'] = test_data['reviews'].apply(mecab.morphs)\n",
        "# test_data['tokenized'] = test_data['tokenized'].apply(lambda x: [item for item in x if item not in stopwords])"
      ],
      "metadata": {
        "id": "TwwlfXt3GQhT"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "negative_words = np.hstack(train_data[train_data.label == 0]['tokenized'].values)\n",
        "positive_words = np.hstack(train_data[train_data.label == 1]['tokenized'].values)"
      ],
      "metadata": {
        "id": "UlhvqwFvGc6T"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "negative_word_count = Counter(negative_words)\n",
        "print(negative_word_count.most_common(20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iUzjV3jGnrn",
        "outputId": "637b9c3f-3dae-4a9a-eff9-3b35347e3026"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('네요', 5241), ('안', 3373), ('는데', 3360), ('어요', 2568), ('있', 2222), ('너무', 2157), ('좋', 1623), ('배송', 1621), ('구매', 1553), ('같', 1478), ('없', 1471), ('되', 1434), ('아요', 1433), ('잘', 1374), ('그냥', 1373), ('않', 1278), ('요', 1270), ('나', 1253), ('만', 1140), ('로', 1073)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "positive_word_count = Counter(positive_words)\n",
        "print(positive_word_count.most_common(20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ya-XTcYRqFh6",
        "outputId": "6809e3a6-7190-4211-9954-a9c773b0b631"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('좋', 6531), ('아요', 3515), ('네요', 3291), ('잘', 3190), ('어요', 3091), ('구매', 2670), ('있', 2145), ('배송', 1993), ('는데', 1957), ('먹', 1625), ('합니다', 1589), ('재', 1533), ('너무', 1434), ('같', 1365), ('만족', 1206), ('쓰', 1132), ('아', 1054), ('해서', 996), ('사용', 970), ('았', 929)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(negative_word_count))\n",
        "print(len(positive_word_count))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDakeTklGobr",
        "outputId": "40cea2de-f37c-4665-f6f1-026c9e86489d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13527\n",
            "10460\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig,(ax1,ax2,ax3,ax4,ax5) = plt.subplots(1,5,figsize=(10,5))\n",
        "\n",
        "axlist=[0,ax1,ax2,ax3,ax4,ax5]\n",
        "\n",
        "for i in range(1, 6):\n",
        "  text_len = train_data[train_data['target']==i]['tokenized'].map(lambda x: len(x))\n",
        "  axlist[i].hist(text_len, color='red')\n",
        "  axlist[i].set_title('score:{} Reviews'.format(i))\n",
        "  axlist[i].set_xlabel('length of samples')\n",
        "  axlist[i].set_ylabel('number of samples')\n",
        "  print('평점 : {}점의 평균 길이 :'.format(i), np.mean(text_len))\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "AeemHgx5Grbj",
        "outputId": "73241bd0-d628-48ee-ad9f-fc3fabbe8dcc"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "평점 : 1점의 평균 길이 : 17.338519671038007\n",
            "평점 : 2점의 평균 길이 : 16.151125\n",
            "평점 : 3점의 평균 길이 : nan\n",
            "평점 : 4점의 평균 길이 : 13.9672\n",
            "평점 : 5점의 평균 길이 : 12.9144\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_data['tokenized'].values\n",
        "train_data1 = pd.get_dummies(train_data['target'])"
      ],
      "metadata": {
        "id": "1TxMd-RrG2Rx"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = train_data1.values\n",
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jo6c8rZcXOD",
        "outputId": "94f7fc91-b24c-40cb-ea2c-f80c2baa0a43"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 0, 0],\n",
              "       [1, 0, 0, 0],\n",
              "       [0, 1, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 1, 0],\n",
              "       [0, 1, 0, 0],\n",
              "       [0, 0, 0, 1]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nx71eGlJZj7R",
        "outputId": "086a3d5f-7992-4e4a-8110-b7f977a39005"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24999, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#정수인코딩\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)"
      ],
      "metadata": {
        "id": "sO49ss6ZHOy1"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 2\n",
        "total_cnt = len(tokenizer.word_index) # 단어의 수\n",
        "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
        "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
        "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
        "\n",
        "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
        "for key, value in tokenizer.word_counts.items():\n",
        "    total_freq = total_freq + value\n",
        "\n",
        "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
        "    if(value < threshold):\n",
        "        rare_cnt = rare_cnt + 1\n",
        "        rare_freq = rare_freq + value\n",
        "\n",
        "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
        "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
        "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
        "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9ByQl9-HZtu",
        "outputId": "cdef0ef4-6f8e-46c5-b70a-80c77cccf629"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합(vocabulary)의 크기 : 17529\n",
            "등장 빈도가 1번 이하인 희귀 단어의 수: 8171\n",
            "단어 집합에서 희귀 단어의 비율: 46.61418221233385\n",
            "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 2.2007827040188324\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 전체 단어 개수 중 빈도수 2이하인 단어 개수는 제거.\n",
        "# 0번 패딩 토큰과 1번 OOV 토큰을 고려하여 +2\n",
        "vocab_size = total_cnt - rare_cnt + 2\n",
        "print('단어 집합의 크기 :',vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dee_qxzJHbjn",
        "outputId": "420ea977-853a-445c-c63b-79302e6c372f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합의 크기 : 9360\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yythMP7sWmkM",
        "outputId": "c3ec4e6c-8598-4f5e-b25b-2d93c01a8d83"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 24999 entries, 0 to 24999\n",
            "Data columns (total 5 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   id         24999 non-null  int64 \n",
            " 1   reviews    24999 non-null  object\n",
            " 2   target     24999 non-null  int64 \n",
            " 3   label      24999 non-null  int64 \n",
            " 4   tokenized  24999 non-null  object\n",
            "dtypes: int64(3), object(2)\n",
            "memory usage: 1.1+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(vocab_size, oov_token = 'OOV') \n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "# X_test = tokenizer.texts_to_sequences(X_test)"
      ],
      "metadata": {
        "id": "YMQ17zzEHh5U"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PJo1VkbHozK",
        "outputId": "17aee0d2-649f-4717-cd6c-1e91208a77b7"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[354, 18, 147, 115, 170, 312, 4], [40, 30, 7, 10, 771, 1, 2530, 298, 892, 10, 387, 5, 70, 386, 171, 2412, 31, 1402, 12, 586, 2], [148, 80, 143, 84, 1274, 39, 183, 5, 79, 71, 199, 54, 84, 1876, 8, 866, 1274, 4402, 8, 2, 86, 175, 42, 41, 19, 452, 11, 472, 266, 340, 180, 4]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#패딩 작업\n",
        "\n",
        "print('리뷰의 최대 길이 :',max(len(review) for review in X_train))\n",
        "print('리뷰의 평균 길이 :',sum(map(len, X_train))/len(X_train))\n",
        "plt.hist([len(review) for review in X_train], bins=50)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "Rla4oa4YHu_K",
        "outputId": "9218f071-3030-4336-8174-9dfd5128b9a9"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "리뷰의 최대 길이 : 73\n",
            "리뷰의 평균 길이 : 14.851674066962678\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def below_threshold_len(max_len, nested_list):\n",
        "  count = 0\n",
        "  for sentence in nested_list:\n",
        "    if(len(sentence) <= max_len):\n",
        "        count = count + 1\n",
        "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (count / len(nested_list))*100))"
      ],
      "metadata": {
        "id": "1ckP9JnOH2I8"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 60\n",
        "below_threshold_len(max_len, X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0FVVMO2H4B5",
        "outputId": "e5d46c35-b94b-449c-8099-abdfd80d7a99"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 샘플 중 길이가 60 이하인 샘플의 비율: 99.98399935997439\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = pad_sequences(X_train, maxlen=max_len)\n",
        "# X_test = pad_sequences(X_test, maxlen=max_len)"
      ],
      "metadata": {
        "id": "TnVwsOKUH8BB"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"{:.4f}\".format(0.3333333333))\n",
        "print('{:>4}'.format(3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7xVkYTDwLnV",
        "outputId": "86414a49-5319-4d51-a50f-78fb802f97ca"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.3333\n",
            "   3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Embedding, Dense, GRU, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "model_num = 1\n",
        "max_acc = 0\n",
        "best_model_num = 0\n",
        "best_hu = 0\n",
        "best_du = 0\n",
        "best_batch = 0\n",
        "\n",
        "for hu in [2**i for i in range(6, 10)]:\n",
        "  embedding_dim = 100\n",
        "  hidden_units = hu\n",
        "  for du in [2**i for i in range(5, 9) if 2**i<hu]:\n",
        "    # tf.keras.layers.Dense(units=24, activation=\"relu\"), \n",
        "    # tf.keras.layers.Dense(units=12, activation=\"relu\"), \n",
        "    model = Sequential()\n",
        "    # model.add(GRU(units=50, activation=\"relu\", return_sequences=True, input_shape = (X_train.shape[1], 5)))\n",
        "    model.add(Embedding(vocab_size, embedding_dim))\n",
        "    model.add(GRU(hidden_units))\n",
        "    model.add(Dense(du, activation='relu'))\n",
        "    model.add(Dense(4, activation='softmax'))\n",
        "\n",
        "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
        "    mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
        "\n",
        "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
        "    # model.summary()\n",
        "\n",
        "    for batch in [16, 32, 64]:\n",
        "      hist = model.fit(X_train, y_train, epochs=15, callbacks=[es, mc], batch_size=batch, validation_split=0.2)\n",
        "      \n",
        "      if max(list(hist.history['val_acc']))>max_acc:\n",
        "        max_acc = max(list(hist.history['val_acc']))\n",
        "        best_model_num = model_num\n",
        "        best_hu, best_du, best_batch = hu, du, batch\n",
        "      \n",
        "      model_num+=1\n",
        "\n",
        "print(\"best model is model_num : {} and the best val_acc score is {:.4f}\".format(best_model_num, max_acc))\n",
        "print(\"best hidden units, dense layer, batch is {}, {}, {}\".format(best_hu, best_du, best_batch))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9Ox5qsHH-0v",
        "outputId": "4fc2302a-f5e7-49ec-f368-a79545b5df82"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.9262 - acc: 0.6148\n",
            "Epoch 1: val_acc improved from -inf to 0.64720, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 12s 8ms/step - loss: 0.9261 - acc: 0.6148 - val_loss: 0.8365 - val_acc: 0.6472\n",
            "Epoch 2/15\n",
            "1244/1250 [============================>.] - ETA: 0s - loss: 0.8099 - acc: 0.6598\n",
            "Epoch 2: val_acc improved from 0.64720 to 0.66080, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.8100 - acc: 0.6596 - val_loss: 0.8118 - val_acc: 0.6608\n",
            "Epoch 3/15\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 0.7539 - acc: 0.6934\n",
            "Epoch 3: val_acc improved from 0.66080 to 0.66400, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.7539 - acc: 0.6932 - val_loss: 0.8124 - val_acc: 0.6640\n",
            "Epoch 4/15\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 0.7061 - acc: 0.7156\n",
            "Epoch 4: val_acc improved from 0.66400 to 0.66880, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.7064 - acc: 0.7155 - val_loss: 0.8079 - val_acc: 0.6688\n",
            "Epoch 5/15\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.6648 - acc: 0.7375\n",
            "Epoch 5: val_acc did not improve from 0.66880\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.6648 - acc: 0.7374 - val_loss: 0.8338 - val_acc: 0.6632\n",
            "Epoch 6/15\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.6236 - acc: 0.7546\n",
            "Epoch 6: val_acc did not improve from 0.66880\n",
            "1250/1250 [==============================] - 9s 8ms/step - loss: 0.6235 - acc: 0.7546 - val_loss: 0.8788 - val_acc: 0.6528\n",
            "Epoch 7/15\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 0.5843 - acc: 0.7772\n",
            "Epoch 7: val_acc did not improve from 0.66880\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.5841 - acc: 0.7772 - val_loss: 0.9277 - val_acc: 0.6448\n",
            "Epoch 8/15\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.5415 - acc: 0.7955\n",
            "Epoch 8: val_acc did not improve from 0.66880\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.5413 - acc: 0.7955 - val_loss: 1.0047 - val_acc: 0.6358\n",
            "Epoch 9/15\n",
            "1244/1250 [============================>.] - ETA: 0s - loss: 0.5034 - acc: 0.8133\n",
            "Epoch 9: val_acc did not improve from 0.66880\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.5031 - acc: 0.8135 - val_loss: 1.0204 - val_acc: 0.6330\n",
            "Epoch 9: early stopping\n",
            "Epoch 1/15\n",
            "619/625 [============================>.] - ETA: 0s - loss: 0.4458 - acc: 0.8365\n",
            "Epoch 1: val_acc did not improve from 0.66880\n",
            "625/625 [==============================] - 5s 7ms/step - loss: 0.4461 - acc: 0.8363 - val_loss: 1.0686 - val_acc: 0.6222\n",
            "Epoch 2/15\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.4025 - acc: 0.8525\n",
            "Epoch 2: val_acc did not improve from 0.66880\n",
            "625/625 [==============================] - 4s 7ms/step - loss: 0.4025 - acc: 0.8525 - val_loss: 1.1736 - val_acc: 0.6028\n",
            "Epoch 3/15\n",
            "621/625 [============================>.] - ETA: 0s - loss: 0.3643 - acc: 0.8691\n",
            "Epoch 3: val_acc did not improve from 0.66880\n",
            "625/625 [==============================] - 4s 7ms/step - loss: 0.3645 - acc: 0.8691 - val_loss: 1.2445 - val_acc: 0.6054\n",
            "Epoch 4/15\n",
            "623/625 [============================>.] - ETA: 0s - loss: 0.3266 - acc: 0.8801\n",
            "Epoch 4: val_acc did not improve from 0.66880\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.3262 - acc: 0.8803 - val_loss: 1.3762 - val_acc: 0.6052\n",
            "Epoch 5/15\n",
            "619/625 [============================>.] - ETA: 0s - loss: 0.2931 - acc: 0.8953\n",
            "Epoch 5: val_acc did not improve from 0.66880\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.2939 - acc: 0.8951 - val_loss: 1.5173 - val_acc: 0.5844\n",
            "Epoch 6/15\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.2619 - acc: 0.9058\n",
            "Epoch 6: val_acc did not improve from 0.66880\n",
            "625/625 [==============================] - 5s 7ms/step - loss: 0.2621 - acc: 0.9058 - val_loss: 1.5759 - val_acc: 0.5886\n",
            "Epoch 6: early stopping\n",
            "Epoch 1/15\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.2230 - acc: 0.9201\n",
            "Epoch 1: val_acc did not improve from 0.66880\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.2230 - acc: 0.9201 - val_loss: 1.7542 - val_acc: 0.5810\n",
            "Epoch 2/15\n",
            "310/313 [============================>.] - ETA: 0s - loss: 0.1919 - acc: 0.9322\n",
            "Epoch 2: val_acc did not improve from 0.66880\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.1929 - acc: 0.9319 - val_loss: 1.9682 - val_acc: 0.5674\n",
            "Epoch 3/15\n",
            "310/313 [============================>.] - ETA: 0s - loss: 0.1676 - acc: 0.9411\n",
            "Epoch 3: val_acc did not improve from 0.66880\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.1677 - acc: 0.9410 - val_loss: 2.1304 - val_acc: 0.5770\n",
            "Epoch 4/15\n",
            "310/313 [============================>.] - ETA: 0s - loss: 0.1462 - acc: 0.9484\n",
            "Epoch 4: val_acc did not improve from 0.66880\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.1463 - acc: 0.9483 - val_loss: 2.3430 - val_acc: 0.5480\n",
            "Epoch 5/15\n",
            "312/313 [============================>.] - ETA: 0s - loss: 0.1284 - acc: 0.9543\n",
            "Epoch 5: val_acc did not improve from 0.66880\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.1284 - acc: 0.9543 - val_loss: 2.4323 - val_acc: 0.5546\n",
            "Epoch 6/15\n",
            "307/313 [============================>.] - ETA: 0s - loss: 0.1122 - acc: 0.9611\n",
            "Epoch 6: val_acc did not improve from 0.66880\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.1120 - acc: 0.9611 - val_loss: 2.6607 - val_acc: 0.5560\n",
            "Epoch 6: early stopping\n",
            "Epoch 1/15\n",
            "1244/1250 [============================>.] - ETA: 0s - loss: 0.9237 - acc: 0.6112\n",
            "Epoch 1: val_acc improved from -inf to 0.65260, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 13s 9ms/step - loss: 0.9232 - acc: 0.6115 - val_loss: 0.8378 - val_acc: 0.6526\n",
            "Epoch 2/15\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.8066 - acc: 0.6598\n",
            "Epoch 2: val_acc improved from 0.65260 to 0.66260, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.8065 - acc: 0.6599 - val_loss: 0.8103 - val_acc: 0.6626\n",
            "Epoch 3/15\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.7521 - acc: 0.6891\n",
            "Epoch 3: val_acc improved from 0.66260 to 0.66640, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 11s 8ms/step - loss: 0.7518 - acc: 0.6892 - val_loss: 0.8029 - val_acc: 0.6664\n",
            "Epoch 4/15\n",
            "1244/1250 [============================>.] - ETA: 0s - loss: 0.7055 - acc: 0.7127\n",
            "Epoch 4: val_acc did not improve from 0.66640\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.7060 - acc: 0.7125 - val_loss: 0.8285 - val_acc: 0.6566\n",
            "Epoch 5/15\n",
            "1244/1250 [============================>.] - ETA: 0s - loss: 0.6617 - acc: 0.7356\n",
            "Epoch 5: val_acc did not improve from 0.66640\n",
            "1250/1250 [==============================] - 12s 9ms/step - loss: 0.6614 - acc: 0.7357 - val_loss: 0.8638 - val_acc: 0.6572\n",
            "Epoch 6/15\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 0.6122 - acc: 0.7632\n",
            "Epoch 6: val_acc did not improve from 0.66640\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.6122 - acc: 0.7631 - val_loss: 0.8796 - val_acc: 0.6572\n",
            "Epoch 7/15\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.5659 - acc: 0.7828\n",
            "Epoch 7: val_acc did not improve from 0.66640\n",
            "1250/1250 [==============================] - 11s 8ms/step - loss: 0.5659 - acc: 0.7828 - val_loss: 0.8979 - val_acc: 0.6614\n",
            "Epoch 8/15\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 0.5139 - acc: 0.8061\n",
            "Epoch 8: val_acc did not improve from 0.66640\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.5137 - acc: 0.8062 - val_loss: 0.9927 - val_acc: 0.6322\n",
            "Epoch 8: early stopping\n",
            "Epoch 1/15\n",
            "619/625 [============================>.] - ETA: 0s - loss: 0.4452 - acc: 0.8349\n",
            "Epoch 1: val_acc did not improve from 0.66640\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.4451 - acc: 0.8348 - val_loss: 1.0766 - val_acc: 0.6244\n",
            "Epoch 2/15\n",
            "621/625 [============================>.] - ETA: 0s - loss: 0.3888 - acc: 0.8586\n",
            "Epoch 2: val_acc did not improve from 0.66640\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.3891 - acc: 0.8585 - val_loss: 1.2047 - val_acc: 0.6164\n",
            "Epoch 3/15\n",
            "619/625 [============================>.] - ETA: 0s - loss: 0.3376 - acc: 0.8768\n",
            "Epoch 3: val_acc did not improve from 0.66640\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.3372 - acc: 0.8768 - val_loss: 1.3706 - val_acc: 0.6020\n",
            "Epoch 4/15\n",
            "619/625 [============================>.] - ETA: 0s - loss: 0.2908 - acc: 0.8954\n",
            "Epoch 4: val_acc did not improve from 0.66640\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.2912 - acc: 0.8953 - val_loss: 1.5577 - val_acc: 0.5842\n",
            "Epoch 5/15\n",
            "622/625 [============================>.] - ETA: 0s - loss: 0.2493 - acc: 0.9066\n",
            "Epoch 5: val_acc did not improve from 0.66640\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.2497 - acc: 0.9066 - val_loss: 1.8130 - val_acc: 0.5942\n",
            "Epoch 6/15\n",
            "621/625 [============================>.] - ETA: 0s - loss: 0.2145 - acc: 0.9200\n",
            "Epoch 6: val_acc did not improve from 0.66640\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.2153 - acc: 0.9195 - val_loss: 1.9138 - val_acc: 0.5710\n",
            "Epoch 6: early stopping\n",
            "Epoch 1/15\n",
            "309/313 [============================>.] - ETA: 0s - loss: 0.1682 - acc: 0.9382\n",
            "Epoch 1: val_acc did not improve from 0.66640\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1681 - acc: 0.9382 - val_loss: 2.1826 - val_acc: 0.5838\n",
            "Epoch 2/15\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.1399 - acc: 0.9486\n",
            "Epoch 2: val_acc did not improve from 0.66640\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1399 - acc: 0.9486 - val_loss: 2.4030 - val_acc: 0.5738\n",
            "Epoch 3/15\n",
            "312/313 [============================>.] - ETA: 0s - loss: 0.1137 - acc: 0.9579\n",
            "Epoch 3: val_acc did not improve from 0.66640\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1136 - acc: 0.9579 - val_loss: 2.7898 - val_acc: 0.5708\n",
            "Epoch 4/15\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.0947 - acc: 0.9653\n",
            "Epoch 4: val_acc did not improve from 0.66640\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0947 - acc: 0.9653 - val_loss: 2.8901 - val_acc: 0.5570\n",
            "Epoch 5/15\n",
            "309/313 [============================>.] - ETA: 0s - loss: 0.0770 - acc: 0.9722\n",
            "Epoch 5: val_acc did not improve from 0.66640\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0772 - acc: 0.9721 - val_loss: 3.2438 - val_acc: 0.5510\n",
            "Epoch 6/15\n",
            "307/313 [============================>.] - ETA: 0s - loss: 0.0642 - acc: 0.9765\n",
            "Epoch 6: val_acc did not improve from 0.66640\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0640 - acc: 0.9765 - val_loss: 3.5928 - val_acc: 0.5612\n",
            "Epoch 6: early stopping\n",
            "Epoch 1/15\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 0.9240 - acc: 0.6154\n",
            "Epoch 1: val_acc improved from -inf to 0.63100, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 13s 9ms/step - loss: 0.9235 - acc: 0.6155 - val_loss: 0.8534 - val_acc: 0.6310\n",
            "Epoch 2/15\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.8076 - acc: 0.6623\n",
            "Epoch 2: val_acc improved from 0.63100 to 0.66620, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 11s 8ms/step - loss: 0.8076 - acc: 0.6623 - val_loss: 0.8059 - val_acc: 0.6662\n",
            "Epoch 3/15\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.7470 - acc: 0.6937\n",
            "Epoch 3: val_acc improved from 0.66620 to 0.66660, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 11s 8ms/step - loss: 0.7470 - acc: 0.6937 - val_loss: 0.8374 - val_acc: 0.6666\n",
            "Epoch 4/15\n",
            "1243/1250 [============================>.] - ETA: 0s - loss: 0.6987 - acc: 0.7195\n",
            "Epoch 4: val_acc did not improve from 0.66660\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.6987 - acc: 0.7195 - val_loss: 0.8268 - val_acc: 0.6646\n",
            "Epoch 5/15\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 0.6541 - acc: 0.7433\n",
            "Epoch 5: val_acc improved from 0.66660 to 0.66740, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 11s 8ms/step - loss: 0.6542 - acc: 0.7432 - val_loss: 0.8437 - val_acc: 0.6674\n",
            "Epoch 6/15\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 0.6085 - acc: 0.7637\n",
            "Epoch 6: val_acc did not improve from 0.66740\n",
            "1250/1250 [==============================] - 11s 8ms/step - loss: 0.6085 - acc: 0.7638 - val_loss: 0.8868 - val_acc: 0.6580\n",
            "Epoch 7/15\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.5585 - acc: 0.7885\n",
            "Epoch 7: val_acc did not improve from 0.66740\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.5585 - acc: 0.7885 - val_loss: 0.9691 - val_acc: 0.6542\n",
            "Epoch 7: early stopping\n",
            "Epoch 1/15\n",
            "623/625 [============================>.] - ETA: 0s - loss: 0.4882 - acc: 0.8170\n",
            "Epoch 1: val_acc did not improve from 0.66740\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.4884 - acc: 0.8168 - val_loss: 0.9896 - val_acc: 0.6370\n",
            "Epoch 2/15\n",
            "620/625 [============================>.] - ETA: 0s - loss: 0.4275 - acc: 0.8413\n",
            "Epoch 2: val_acc did not improve from 0.66740\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.4285 - acc: 0.8409 - val_loss: 1.0516 - val_acc: 0.6322\n",
            "Epoch 3/15\n",
            "620/625 [============================>.] - ETA: 0s - loss: 0.3742 - acc: 0.8612\n",
            "Epoch 3: val_acc did not improve from 0.66740\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.3740 - acc: 0.8612 - val_loss: 1.2394 - val_acc: 0.6126\n",
            "Epoch 4/15\n",
            "623/625 [============================>.] - ETA: 0s - loss: 0.3240 - acc: 0.8831\n",
            "Epoch 4: val_acc did not improve from 0.66740\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.3237 - acc: 0.8833 - val_loss: 1.4017 - val_acc: 0.6052\n",
            "Epoch 5/15\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.2776 - acc: 0.8976\n",
            "Epoch 5: val_acc did not improve from 0.66740\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.2776 - acc: 0.8976 - val_loss: 1.6443 - val_acc: 0.5866\n",
            "Epoch 6/15\n",
            "621/625 [============================>.] - ETA: 0s - loss: 0.2375 - acc: 0.9121\n",
            "Epoch 6: val_acc did not improve from 0.66740\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.2378 - acc: 0.9119 - val_loss: 1.8067 - val_acc: 0.5800\n",
            "Epoch 6: early stopping\n",
            "Epoch 1/15\n",
            "311/313 [============================>.] - ETA: 0s - loss: 0.1847 - acc: 0.9330\n",
            "Epoch 1: val_acc did not improve from 0.66740\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1851 - acc: 0.9327 - val_loss: 2.0034 - val_acc: 0.5806\n",
            "Epoch 2/15\n",
            "309/313 [============================>.] - ETA: 0s - loss: 0.1497 - acc: 0.9444\n",
            "Epoch 2: val_acc did not improve from 0.66740\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1499 - acc: 0.9443 - val_loss: 2.2294 - val_acc: 0.5828\n",
            "Epoch 3/15\n",
            "310/313 [============================>.] - ETA: 0s - loss: 0.1205 - acc: 0.9559\n",
            "Epoch 3: val_acc did not improve from 0.66740\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1206 - acc: 0.9558 - val_loss: 2.5075 - val_acc: 0.5792\n",
            "Epoch 4/15\n",
            "309/313 [============================>.] - ETA: 0s - loss: 0.0977 - acc: 0.9642\n",
            "Epoch 4: val_acc did not improve from 0.66740\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0975 - acc: 0.9643 - val_loss: 2.9108 - val_acc: 0.5732\n",
            "Epoch 5/15\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.0787 - acc: 0.9718\n",
            "Epoch 5: val_acc did not improve from 0.66740\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0787 - acc: 0.9718 - val_loss: 3.0464 - val_acc: 0.5786\n",
            "Epoch 6/15\n",
            "309/313 [============================>.] - ETA: 0s - loss: 0.0632 - acc: 0.9781\n",
            "Epoch 6: val_acc did not improve from 0.66740\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0631 - acc: 0.9782 - val_loss: 3.3744 - val_acc: 0.5654\n",
            "Epoch 6: early stopping\n",
            "Epoch 1/15\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 0.9308 - acc: 0.6150\n",
            "Epoch 1: val_acc improved from -inf to 0.63760, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 13s 9ms/step - loss: 0.9308 - acc: 0.6148 - val_loss: 0.8436 - val_acc: 0.6376\n",
            "Epoch 2/15\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.8035 - acc: 0.6637\n",
            "Epoch 2: val_acc improved from 0.63760 to 0.67720, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.8039 - acc: 0.6636 - val_loss: 0.7950 - val_acc: 0.6772\n",
            "Epoch 3/15\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 0.7439 - acc: 0.6935\n",
            "Epoch 3: val_acc did not improve from 0.67720\n",
            "1250/1250 [==============================] - 11s 8ms/step - loss: 0.7436 - acc: 0.6936 - val_loss: 0.8131 - val_acc: 0.6660\n",
            "Epoch 4/15\n",
            "1244/1250 [============================>.] - ETA: 0s - loss: 0.6974 - acc: 0.7172\n",
            "Epoch 4: val_acc did not improve from 0.67720\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.6976 - acc: 0.7171 - val_loss: 0.8557 - val_acc: 0.6414\n",
            "Epoch 5/15\n",
            "1244/1250 [============================>.] - ETA: 0s - loss: 0.6509 - acc: 0.7407\n",
            "Epoch 5: val_acc did not improve from 0.67720\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.6510 - acc: 0.7407 - val_loss: 0.8147 - val_acc: 0.6684\n",
            "Epoch 6/15\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 0.5982 - acc: 0.7692\n",
            "Epoch 6: val_acc did not improve from 0.67720\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.5981 - acc: 0.7691 - val_loss: 0.9374 - val_acc: 0.6446\n",
            "Epoch 7/15\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.5425 - acc: 0.7925\n",
            "Epoch 7: val_acc did not improve from 0.67720\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.5425 - acc: 0.7925 - val_loss: 0.9671 - val_acc: 0.6474\n",
            "Epoch 7: early stopping\n",
            "Epoch 1/15\n",
            "623/625 [============================>.] - ETA: 0s - loss: 0.4534 - acc: 0.8298\n",
            "Epoch 1: val_acc did not improve from 0.67720\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.4536 - acc: 0.8295 - val_loss: 1.0947 - val_acc: 0.6042\n",
            "Epoch 2/15\n",
            "622/625 [============================>.] - ETA: 0s - loss: 0.3844 - acc: 0.8572\n",
            "Epoch 2: val_acc did not improve from 0.67720\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.3846 - acc: 0.8571 - val_loss: 1.1744 - val_acc: 0.6292\n",
            "Epoch 3/15\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.3224 - acc: 0.8819\n",
            "Epoch 3: val_acc did not improve from 0.67720\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.3224 - acc: 0.8819 - val_loss: 1.3319 - val_acc: 0.5998\n",
            "Epoch 4/15\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.2645 - acc: 0.9044\n",
            "Epoch 4: val_acc did not improve from 0.67720\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.2643 - acc: 0.9046 - val_loss: 1.6317 - val_acc: 0.6064\n",
            "Epoch 5/15\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.2107 - acc: 0.9222\n",
            "Epoch 5: val_acc did not improve from 0.67720\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.2107 - acc: 0.9222 - val_loss: 1.7814 - val_acc: 0.5866\n",
            "Epoch 6/15\n",
            "623/625 [============================>.] - ETA: 0s - loss: 0.1661 - acc: 0.9385\n",
            "Epoch 6: val_acc did not improve from 0.67720\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.1660 - acc: 0.9385 - val_loss: 2.2191 - val_acc: 0.5880\n",
            "Epoch 6: early stopping\n",
            "Epoch 1/15\n",
            "311/313 [============================>.] - ETA: 0s - loss: 0.1153 - acc: 0.9591\n",
            "Epoch 1: val_acc did not improve from 0.67720\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.1152 - acc: 0.9591 - val_loss: 2.5439 - val_acc: 0.5732\n",
            "Epoch 2/15\n",
            "312/313 [============================>.] - ETA: 0s - loss: 0.0837 - acc: 0.9702\n",
            "Epoch 2: val_acc did not improve from 0.67720\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0841 - acc: 0.9700 - val_loss: 2.7970 - val_acc: 0.5656\n",
            "Epoch 3/15\n",
            "308/313 [============================>.] - ETA: 0s - loss: 0.0596 - acc: 0.9785\n",
            "Epoch 3: val_acc did not improve from 0.67720\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0594 - acc: 0.9785 - val_loss: 3.3597 - val_acc: 0.5474\n",
            "Epoch 4/15\n",
            "309/313 [============================>.] - ETA: 0s - loss: 0.0453 - acc: 0.9835\n",
            "Epoch 4: val_acc did not improve from 0.67720\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0455 - acc: 0.9834 - val_loss: 3.5347 - val_acc: 0.5660\n",
            "Epoch 5/15\n",
            "307/313 [============================>.] - ETA: 0s - loss: 0.0336 - acc: 0.9896\n",
            "Epoch 5: val_acc did not improve from 0.67720\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0335 - acc: 0.9896 - val_loss: 3.7901 - val_acc: 0.5642\n",
            "Epoch 6/15\n",
            "309/313 [============================>.] - ETA: 0s - loss: 0.0259 - acc: 0.9915\n",
            "Epoch 6: val_acc did not improve from 0.67720\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0259 - acc: 0.9914 - val_loss: 4.1377 - val_acc: 0.5434\n",
            "Epoch 6: early stopping\n",
            "Epoch 1/15\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.9331 - acc: 0.6136\n",
            "Epoch 1: val_acc improved from -inf to 0.65280, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 13s 9ms/step - loss: 0.9329 - acc: 0.6137 - val_loss: 0.8367 - val_acc: 0.6528\n",
            "Epoch 2/15\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 0.8073 - acc: 0.6600\n",
            "Epoch 2: val_acc improved from 0.65280 to 0.65980, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.8073 - acc: 0.6598 - val_loss: 0.8348 - val_acc: 0.6598\n",
            "Epoch 3/15\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.7498 - acc: 0.6890\n",
            "Epoch 3: val_acc improved from 0.65980 to 0.66980, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.7498 - acc: 0.6890 - val_loss: 0.8011 - val_acc: 0.6698\n",
            "Epoch 4/15\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 0.6985 - acc: 0.7189\n",
            "Epoch 4: val_acc improved from 0.66980 to 0.67380, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.6980 - acc: 0.7190 - val_loss: 0.8314 - val_acc: 0.6738\n",
            "Epoch 5/15\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 0.6489 - acc: 0.7440\n",
            "Epoch 5: val_acc did not improve from 0.67380\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.6493 - acc: 0.7438 - val_loss: 0.8886 - val_acc: 0.6494\n",
            "Epoch 6/15\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.5935 - acc: 0.7703\n",
            "Epoch 6: val_acc did not improve from 0.67380\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.5936 - acc: 0.7702 - val_loss: 0.8849 - val_acc: 0.6514\n",
            "Epoch 7/15\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.5359 - acc: 0.7974\n",
            "Epoch 7: val_acc did not improve from 0.67380\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.5358 - acc: 0.7975 - val_loss: 0.9800 - val_acc: 0.6392\n",
            "Epoch 8/15\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 0.4671 - acc: 0.8261\n",
            "Epoch 8: val_acc did not improve from 0.67380\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.4670 - acc: 0.8262 - val_loss: 1.1175 - val_acc: 0.6200\n",
            "Epoch 8: early stopping\n",
            "Epoch 1/15\n",
            "621/625 [============================>.] - ETA: 0s - loss: 0.3703 - acc: 0.8632\n",
            "Epoch 1: val_acc did not improve from 0.67380\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.3703 - acc: 0.8633 - val_loss: 1.3116 - val_acc: 0.6264\n",
            "Epoch 2/15\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.2954 - acc: 0.8913\n",
            "Epoch 2: val_acc did not improve from 0.67380\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.2954 - acc: 0.8913 - val_loss: 1.5775 - val_acc: 0.5778\n",
            "Epoch 3/15\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.2353 - acc: 0.9111\n",
            "Epoch 3: val_acc did not improve from 0.67380\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.2353 - acc: 0.9111 - val_loss: 1.8835 - val_acc: 0.5990\n",
            "Epoch 4/15\n",
            "622/625 [============================>.] - ETA: 0s - loss: 0.1850 - acc: 0.9319\n",
            "Epoch 4: val_acc did not improve from 0.67380\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.1848 - acc: 0.9320 - val_loss: 2.1995 - val_acc: 0.5936\n",
            "Epoch 5/15\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.1429 - acc: 0.9488\n",
            "Epoch 5: val_acc did not improve from 0.67380\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.1429 - acc: 0.9488 - val_loss: 2.3511 - val_acc: 0.5914\n",
            "Epoch 6/15\n",
            "620/625 [============================>.] - ETA: 0s - loss: 0.1088 - acc: 0.9601\n",
            "Epoch 6: val_acc did not improve from 0.67380\n",
            "625/625 [==============================] - 7s 11ms/step - loss: 0.1098 - acc: 0.9598 - val_loss: 2.9545 - val_acc: 0.5684\n",
            "Epoch 6: early stopping\n",
            "Epoch 1/15\n",
            "307/313 [============================>.] - ETA: 0s - loss: 0.0693 - acc: 0.9749\n",
            "Epoch 1: val_acc did not improve from 0.67380\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0692 - acc: 0.9750 - val_loss: 3.1425 - val_acc: 0.5776\n",
            "Epoch 2/15\n",
            "310/313 [============================>.] - ETA: 0s - loss: 0.0480 - acc: 0.9821\n",
            "Epoch 2: val_acc did not improve from 0.67380\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0480 - acc: 0.9821 - val_loss: 3.5203 - val_acc: 0.5720\n",
            "Epoch 3/15\n",
            "308/313 [============================>.] - ETA: 0s - loss: 0.0342 - acc: 0.9882\n",
            "Epoch 3: val_acc did not improve from 0.67380\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0346 - acc: 0.9879 - val_loss: 3.9550 - val_acc: 0.5590\n",
            "Epoch 4/15\n",
            "310/313 [============================>.] - ETA: 0s - loss: 0.0266 - acc: 0.9912\n",
            "Epoch 4: val_acc did not improve from 0.67380\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0268 - acc: 0.9911 - val_loss: 4.1068 - val_acc: 0.5628\n",
            "Epoch 5/15\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.0211 - acc: 0.9935\n",
            "Epoch 5: val_acc did not improve from 0.67380\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0211 - acc: 0.9935 - val_loss: 4.4100 - val_acc: 0.5752\n",
            "Epoch 6/15\n",
            "309/313 [============================>.] - ETA: 0s - loss: 0.0172 - acc: 0.9947\n",
            "Epoch 6: val_acc did not improve from 0.67380\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0173 - acc: 0.9946 - val_loss: 4.7027 - val_acc: 0.5422\n",
            "Epoch 6: early stopping\n",
            "Epoch 1/15\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 0.9206 - acc: 0.6154\n",
            "Epoch 1: val_acc improved from -inf to 0.63780, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 14s 9ms/step - loss: 0.9205 - acc: 0.6154 - val_loss: 0.8344 - val_acc: 0.6378\n",
            "Epoch 2/15\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 0.8027 - acc: 0.6629\n",
            "Epoch 2: val_acc improved from 0.63780 to 0.67220, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.8028 - acc: 0.6627 - val_loss: 0.8031 - val_acc: 0.6722\n",
            "Epoch 3/15\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 0.7458 - acc: 0.6948\n",
            "Epoch 3: val_acc did not improve from 0.67220\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.7462 - acc: 0.6946 - val_loss: 0.8085 - val_acc: 0.6696\n",
            "Epoch 4/15\n",
            "1244/1250 [============================>.] - ETA: 0s - loss: 0.6952 - acc: 0.7202\n",
            "Epoch 4: val_acc did not improve from 0.67220\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.6955 - acc: 0.7203 - val_loss: 0.8420 - val_acc: 0.6618\n",
            "Epoch 5/15\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.6489 - acc: 0.7453\n",
            "Epoch 5: val_acc did not improve from 0.67220\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.6489 - acc: 0.7453 - val_loss: 0.8810 - val_acc: 0.6580\n",
            "Epoch 6/15\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.5944 - acc: 0.7715\n",
            "Epoch 6: val_acc did not improve from 0.67220\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.5944 - acc: 0.7715 - val_loss: 0.9256 - val_acc: 0.6422\n",
            "Epoch 7/15\n",
            "1244/1250 [============================>.] - ETA: 0s - loss: 0.5377 - acc: 0.7977\n",
            "Epoch 7: val_acc did not improve from 0.67220\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.5382 - acc: 0.7974 - val_loss: 0.9824 - val_acc: 0.6438\n",
            "Epoch 7: early stopping\n",
            "Epoch 1/15\n",
            "621/625 [============================>.] - ETA: 0s - loss: 0.4485 - acc: 0.8302\n",
            "Epoch 1: val_acc did not improve from 0.67220\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.4484 - acc: 0.8302 - val_loss: 1.1069 - val_acc: 0.6352\n",
            "Epoch 2/15\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.3763 - acc: 0.8572\n",
            "Epoch 2: val_acc did not improve from 0.67220\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.3761 - acc: 0.8572 - val_loss: 1.3335 - val_acc: 0.6110\n",
            "Epoch 3/15\n",
            "621/625 [============================>.] - ETA: 0s - loss: 0.3087 - acc: 0.8864\n",
            "Epoch 3: val_acc did not improve from 0.67220\n",
            "625/625 [==============================] - 6s 10ms/step - loss: 0.3087 - acc: 0.8864 - val_loss: 1.5325 - val_acc: 0.6020\n",
            "Epoch 4/15\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.2486 - acc: 0.9071\n",
            "Epoch 4: val_acc did not improve from 0.67220\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.2486 - acc: 0.9071 - val_loss: 1.7686 - val_acc: 0.5964\n",
            "Epoch 5/15\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.1962 - acc: 0.9253\n",
            "Epoch 5: val_acc did not improve from 0.67220\n",
            "625/625 [==============================] - 7s 11ms/step - loss: 0.1961 - acc: 0.9252 - val_loss: 2.0835 - val_acc: 0.5962\n",
            "Epoch 6/15\n",
            "619/625 [============================>.] - ETA: 0s - loss: 0.1504 - acc: 0.9432\n",
            "Epoch 6: val_acc did not improve from 0.67220\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.1513 - acc: 0.9428 - val_loss: 2.4570 - val_acc: 0.5736\n",
            "Epoch 6: early stopping\n",
            "Epoch 1/15\n",
            "309/313 [============================>.] - ETA: 0s - loss: 0.0982 - acc: 0.9644\n",
            "Epoch 1: val_acc did not improve from 0.67220\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0981 - acc: 0.9644 - val_loss: 2.9889 - val_acc: 0.5808\n",
            "Epoch 2/15\n",
            "308/313 [============================>.] - ETA: 0s - loss: 0.0690 - acc: 0.9744\n",
            "Epoch 2: val_acc did not improve from 0.67220\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0691 - acc: 0.9744 - val_loss: 3.3242 - val_acc: 0.5764\n",
            "Epoch 3/15\n",
            "312/313 [============================>.] - ETA: 0s - loss: 0.0495 - acc: 0.9828\n",
            "Epoch 3: val_acc did not improve from 0.67220\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0495 - acc: 0.9828 - val_loss: 3.8368 - val_acc: 0.5628\n",
            "Epoch 4/15\n",
            "309/313 [============================>.] - ETA: 0s - loss: 0.0330 - acc: 0.9887\n",
            "Epoch 4: val_acc did not improve from 0.67220\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0334 - acc: 0.9884 - val_loss: 4.3833 - val_acc: 0.5512\n",
            "Epoch 5/15\n",
            "308/313 [============================>.] - ETA: 0s - loss: 0.0262 - acc: 0.9913\n",
            "Epoch 5: val_acc did not improve from 0.67220\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0261 - acc: 0.9913 - val_loss: 4.8042 - val_acc: 0.5678\n",
            "Epoch 6/15\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.0216 - acc: 0.9931\n",
            "Epoch 6: val_acc did not improve from 0.67220\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0216 - acc: 0.9931 - val_loss: 4.8687 - val_acc: 0.5684\n",
            "Epoch 6: early stopping\n",
            "Epoch 1/15\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 0.9581 - acc: 0.6076\n",
            "Epoch 1: val_acc improved from -inf to 0.64180, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 14s 10ms/step - loss: 0.9591 - acc: 0.6074 - val_loss: 0.8471 - val_acc: 0.6418\n",
            "Epoch 2/15\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 0.8210 - acc: 0.6549\n",
            "Epoch 2: val_acc improved from 0.64180 to 0.65740, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 12s 10ms/step - loss: 0.8207 - acc: 0.6552 - val_loss: 0.8250 - val_acc: 0.6574\n",
            "Epoch 3/15\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 0.7516 - acc: 0.6882\n",
            "Epoch 3: val_acc improved from 0.65740 to 0.67220, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 12s 10ms/step - loss: 0.7517 - acc: 0.6881 - val_loss: 0.7984 - val_acc: 0.6722\n",
            "Epoch 4/15\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.8234 - acc: 0.6687\n",
            "Epoch 4: val_acc did not improve from 0.67220\n",
            "1250/1250 [==============================] - 12s 10ms/step - loss: 0.8234 - acc: 0.6686 - val_loss: 0.8401 - val_acc: 0.6540\n",
            "Epoch 5/15\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 0.9700 - acc: 0.6043\n",
            "Epoch 5: val_acc did not improve from 0.67220\n",
            "1250/1250 [==============================] - 12s 10ms/step - loss: 0.9702 - acc: 0.6042 - val_loss: 0.8999 - val_acc: 0.6396\n",
            "Epoch 6/15\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.7604 - acc: 0.6965\n",
            "Epoch 6: val_acc did not improve from 0.67220\n",
            "1250/1250 [==============================] - 12s 10ms/step - loss: 0.7604 - acc: 0.6965 - val_loss: 0.8019 - val_acc: 0.6684\n",
            "Epoch 7/15\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.6682 - acc: 0.7326\n",
            "Epoch 7: val_acc did not improve from 0.67220\n",
            "1250/1250 [==============================] - 12s 10ms/step - loss: 0.6682 - acc: 0.7326 - val_loss: 0.8618 - val_acc: 0.6584\n",
            "Epoch 8/15\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 0.6190 - acc: 0.7561\n",
            "Epoch 8: val_acc did not improve from 0.67220\n",
            "1250/1250 [==============================] - 12s 10ms/step - loss: 0.6189 - acc: 0.7563 - val_loss: 0.9367 - val_acc: 0.6400\n",
            "Epoch 8: early stopping\n",
            "Epoch 1/15\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.5401 - acc: 0.7917\n",
            "Epoch 1: val_acc did not improve from 0.67220\n",
            "625/625 [==============================] - 7s 11ms/step - loss: 0.5400 - acc: 0.7917 - val_loss: 0.9555 - val_acc: 0.6414\n",
            "Epoch 2/15\n",
            "621/625 [============================>.] - ETA: 0s - loss: 0.4632 - acc: 0.8212\n",
            "Epoch 2: val_acc did not improve from 0.67220\n",
            "625/625 [==============================] - 8s 12ms/step - loss: 0.4633 - acc: 0.8209 - val_loss: 1.0964 - val_acc: 0.6292\n",
            "Epoch 3/15\n",
            "620/625 [============================>.] - ETA: 0s - loss: 0.3904 - acc: 0.8501\n",
            "Epoch 3: val_acc did not improve from 0.67220\n",
            "625/625 [==============================] - 8s 12ms/step - loss: 0.3908 - acc: 0.8499 - val_loss: 1.2651 - val_acc: 0.6230\n",
            "Epoch 4/15\n",
            "623/625 [============================>.] - ETA: 0s - loss: 0.3127 - acc: 0.8812\n",
            "Epoch 4: val_acc did not improve from 0.67220\n",
            "625/625 [==============================] - 7s 11ms/step - loss: 0.3126 - acc: 0.8813 - val_loss: 1.4877 - val_acc: 0.6018\n",
            "Epoch 5/15\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.2469 - acc: 0.9052\n",
            "Epoch 5: val_acc did not improve from 0.67220\n",
            "625/625 [==============================] - 8s 12ms/step - loss: 0.2469 - acc: 0.9052 - val_loss: 1.7764 - val_acc: 0.6058\n",
            "Epoch 6/15\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.1879 - acc: 0.9279\n",
            "Epoch 6: val_acc did not improve from 0.67220\n",
            "625/625 [==============================] - 8s 12ms/step - loss: 0.1879 - acc: 0.9279 - val_loss: 2.3033 - val_acc: 0.5924\n",
            "Epoch 6: early stopping\n",
            "Epoch 1/15\n",
            "311/313 [============================>.] - ETA: 0s - loss: 0.1229 - acc: 0.9527\n",
            "Epoch 1: val_acc did not improve from 0.67220\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.1229 - acc: 0.9527 - val_loss: 2.5005 - val_acc: 0.5734\n",
            "Epoch 2/15\n",
            "311/313 [============================>.] - ETA: 0s - loss: 0.0822 - acc: 0.9699\n",
            "Epoch 2: val_acc did not improve from 0.67220\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.0822 - acc: 0.9699 - val_loss: 2.9240 - val_acc: 0.5894\n",
            "Epoch 3/15\n",
            "310/313 [============================>.] - ETA: 0s - loss: 0.0621 - acc: 0.9786\n",
            "Epoch 3: val_acc did not improve from 0.67220\n",
            "313/313 [==============================] - 5s 14ms/step - loss: 0.0621 - acc: 0.9786 - val_loss: 3.2941 - val_acc: 0.5790\n",
            "Epoch 4/15\n",
            "312/313 [============================>.] - ETA: 0s - loss: 0.0434 - acc: 0.9849\n",
            "Epoch 4: val_acc did not improve from 0.67220\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.0433 - acc: 0.9849 - val_loss: 3.6179 - val_acc: 0.5934\n",
            "Epoch 5/15\n",
            "311/313 [============================>.] - ETA: 0s - loss: 0.0304 - acc: 0.9906\n",
            "Epoch 5: val_acc did not improve from 0.67220\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.0304 - acc: 0.9905 - val_loss: 3.9921 - val_acc: 0.5794\n",
            "Epoch 6/15\n",
            "312/313 [============================>.] - ETA: 0s - loss: 0.0262 - acc: 0.9913\n",
            "Epoch 6: val_acc did not improve from 0.67220\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.0261 - acc: 0.9913 - val_loss: 4.0815 - val_acc: 0.5792\n",
            "Epoch 6: early stopping\n",
            "Epoch 1/15\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.9345 - acc: 0.6142\n",
            "Epoch 1: val_acc improved from -inf to 0.65200, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 14s 10ms/step - loss: 0.9344 - acc: 0.6144 - val_loss: 0.8358 - val_acc: 0.6520\n",
            "Epoch 2/15\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.8081 - acc: 0.6582\n",
            "Epoch 2: val_acc improved from 0.65200 to 0.65440, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 13s 10ms/step - loss: 0.8082 - acc: 0.6581 - val_loss: 0.8410 - val_acc: 0.6544\n",
            "Epoch 3/15\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 0.7517 - acc: 0.6843\n",
            "Epoch 3: val_acc improved from 0.65440 to 0.66900, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 12s 10ms/step - loss: 0.7523 - acc: 0.6842 - val_loss: 0.8069 - val_acc: 0.6690\n",
            "Epoch 4/15\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 0.7042 - acc: 0.7164\n",
            "Epoch 4: val_acc did not improve from 0.66900\n",
            "1250/1250 [==============================] - 12s 10ms/step - loss: 0.7041 - acc: 0.7164 - val_loss: 0.8150 - val_acc: 0.6660\n",
            "Epoch 5/15\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 0.6539 - acc: 0.7416\n",
            "Epoch 5: val_acc did not improve from 0.66900\n",
            "1250/1250 [==============================] - 12s 10ms/step - loss: 0.6538 - acc: 0.7415 - val_loss: 0.8507 - val_acc: 0.6510\n",
            "Epoch 6/15\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 0.5970 - acc: 0.7672\n",
            "Epoch 6: val_acc did not improve from 0.66900\n",
            "1250/1250 [==============================] - 12s 10ms/step - loss: 0.5975 - acc: 0.7670 - val_loss: 0.9469 - val_acc: 0.6494\n",
            "Epoch 7/15\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 0.5370 - acc: 0.7949\n",
            "Epoch 7: val_acc did not improve from 0.66900\n",
            "1250/1250 [==============================] - 12s 10ms/step - loss: 0.5376 - acc: 0.7948 - val_loss: 0.9762 - val_acc: 0.6450\n",
            "Epoch 8/15\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 0.4719 - acc: 0.8236\n",
            "Epoch 8: val_acc did not improve from 0.66900\n",
            "1250/1250 [==============================] - 12s 10ms/step - loss: 0.4714 - acc: 0.8238 - val_loss: 1.2194 - val_acc: 0.6264\n",
            "Epoch 8: early stopping\n",
            "Epoch 1/15\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.3665 - acc: 0.8619\n",
            "Epoch 1: val_acc did not improve from 0.66900\n",
            "625/625 [==============================] - 7s 12ms/step - loss: 0.3665 - acc: 0.8619 - val_loss: 1.3310 - val_acc: 0.6124\n",
            "Epoch 2/15\n",
            "623/625 [============================>.] - ETA: 0s - loss: 0.2863 - acc: 0.8935\n",
            "Epoch 2: val_acc did not improve from 0.66900\n",
            "625/625 [==============================] - 7s 11ms/step - loss: 0.2861 - acc: 0.8936 - val_loss: 1.7112 - val_acc: 0.5962\n",
            "Epoch 3/15\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.2224 - acc: 0.9168\n",
            "Epoch 3: val_acc did not improve from 0.66900\n",
            "625/625 [==============================] - 7s 11ms/step - loss: 0.2224 - acc: 0.9168 - val_loss: 1.8458 - val_acc: 0.5896\n",
            "Epoch 4/15\n",
            "622/625 [============================>.] - ETA: 0s - loss: 0.1693 - acc: 0.9348\n",
            "Epoch 4: val_acc did not improve from 0.66900\n",
            "625/625 [==============================] - 8s 12ms/step - loss: 0.1700 - acc: 0.9346 - val_loss: 2.3530 - val_acc: 0.5886\n",
            "Epoch 5/15\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.1235 - acc: 0.9539\n",
            "Epoch 5: val_acc did not improve from 0.66900\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.1236 - acc: 0.9539 - val_loss: 2.7833 - val_acc: 0.5672\n",
            "Epoch 6/15\n",
            "622/625 [============================>.] - ETA: 0s - loss: 0.0966 - acc: 0.9663\n",
            "Epoch 6: val_acc did not improve from 0.66900\n",
            "625/625 [==============================] - 7s 12ms/step - loss: 0.0967 - acc: 0.9663 - val_loss: 3.2474 - val_acc: 0.5842\n",
            "Epoch 6: early stopping\n",
            "Epoch 1/15\n",
            "312/313 [============================>.] - ETA: 0s - loss: 0.0575 - acc: 0.9795\n",
            "Epoch 1: val_acc did not improve from 0.66900\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.0574 - acc: 0.9795 - val_loss: 3.6622 - val_acc: 0.5704\n",
            "Epoch 2/15\n",
            "312/313 [============================>.] - ETA: 0s - loss: 0.0410 - acc: 0.9860\n",
            "Epoch 2: val_acc did not improve from 0.66900\n",
            "313/313 [==============================] - 5s 14ms/step - loss: 0.0410 - acc: 0.9860 - val_loss: 3.9756 - val_acc: 0.5888\n",
            "Epoch 3/15\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.0308 - acc: 0.9900\n",
            "Epoch 3: val_acc did not improve from 0.66900\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.0308 - acc: 0.9900 - val_loss: 4.1976 - val_acc: 0.5720\n",
            "Epoch 4/15\n",
            "310/313 [============================>.] - ETA: 0s - loss: 0.0229 - acc: 0.9926\n",
            "Epoch 4: val_acc did not improve from 0.66900\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.0229 - acc: 0.9926 - val_loss: 4.5044 - val_acc: 0.5724\n",
            "Epoch 5/15\n",
            "310/313 [============================>.] - ETA: 0s - loss: 0.0173 - acc: 0.9936\n",
            "Epoch 5: val_acc did not improve from 0.66900\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.0172 - acc: 0.9936 - val_loss: 5.2957 - val_acc: 0.5692\n",
            "Epoch 6/15\n",
            "311/313 [============================>.] - ETA: 0s - loss: 0.0167 - acc: 0.9948\n",
            "Epoch 6: val_acc did not improve from 0.66900\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.0167 - acc: 0.9947 - val_loss: 5.1396 - val_acc: 0.5588\n",
            "Epoch 6: early stopping\n",
            "Epoch 1/15\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.9369 - acc: 0.6103\n",
            "Epoch 1: val_acc improved from -inf to 0.64580, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 15s 11ms/step - loss: 0.9369 - acc: 0.6103 - val_loss: 0.8327 - val_acc: 0.6458\n",
            "Epoch 2/15\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 0.8093 - acc: 0.6582\n",
            "Epoch 2: val_acc improved from 0.64580 to 0.66080, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 13s 10ms/step - loss: 0.8091 - acc: 0.6583 - val_loss: 0.8365 - val_acc: 0.6608\n",
            "Epoch 3/15\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 0.7519 - acc: 0.6907\n",
            "Epoch 3: val_acc improved from 0.66080 to 0.67380, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 13s 10ms/step - loss: 0.7519 - acc: 0.6906 - val_loss: 0.7981 - val_acc: 0.6738\n",
            "Epoch 4/15\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 0.7029 - acc: 0.7157\n",
            "Epoch 4: val_acc did not improve from 0.67380\n",
            "1250/1250 [==============================] - 13s 10ms/step - loss: 0.7031 - acc: 0.7158 - val_loss: 0.8207 - val_acc: 0.6718\n",
            "Epoch 5/15\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.6494 - acc: 0.7445\n",
            "Epoch 5: val_acc did not improve from 0.67380\n",
            "1250/1250 [==============================] - 12s 10ms/step - loss: 0.6496 - acc: 0.7443 - val_loss: 0.8279 - val_acc: 0.6614\n",
            "Epoch 6/15\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 0.5928 - acc: 0.7720\n",
            "Epoch 6: val_acc did not improve from 0.67380\n",
            "1250/1250 [==============================] - 12s 10ms/step - loss: 0.5923 - acc: 0.7722 - val_loss: 0.9393 - val_acc: 0.6546\n",
            "Epoch 7/15\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 0.5250 - acc: 0.7993\n",
            "Epoch 7: val_acc did not improve from 0.67380\n",
            "1250/1250 [==============================] - 13s 10ms/step - loss: 0.5256 - acc: 0.7990 - val_loss: 1.0437 - val_acc: 0.6382\n",
            "Epoch 8/15\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.4490 - acc: 0.8320\n",
            "Epoch 8: val_acc did not improve from 0.67380\n",
            "1250/1250 [==============================] - 12s 10ms/step - loss: 0.4490 - acc: 0.8318 - val_loss: 1.2492 - val_acc: 0.6072\n",
            "Epoch 8: early stopping\n",
            "Epoch 1/15\n",
            "622/625 [============================>.] - ETA: 0s - loss: 0.3412 - acc: 0.8749\n",
            "Epoch 1: val_acc did not improve from 0.67380\n",
            "625/625 [==============================] - 8s 14ms/step - loss: 0.3414 - acc: 0.8748 - val_loss: 1.4645 - val_acc: 0.6120\n",
            "Epoch 2/15\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.2510 - acc: 0.9081\n",
            "Epoch 2: val_acc did not improve from 0.67380\n",
            "625/625 [==============================] - 7s 12ms/step - loss: 0.2513 - acc: 0.9078 - val_loss: 1.7645 - val_acc: 0.5930\n",
            "Epoch 3/15\n",
            "621/625 [============================>.] - ETA: 0s - loss: 0.1885 - acc: 0.9292\n",
            "Epoch 3: val_acc did not improve from 0.67380\n",
            "625/625 [==============================] - 7s 12ms/step - loss: 0.1891 - acc: 0.9287 - val_loss: 2.1143 - val_acc: 0.5862\n",
            "Epoch 4/15\n",
            "623/625 [============================>.] - ETA: 0s - loss: 0.1354 - acc: 0.9478\n",
            "Epoch 4: val_acc did not improve from 0.67380\n",
            "625/625 [==============================] - 7s 12ms/step - loss: 0.1355 - acc: 0.9477 - val_loss: 2.5165 - val_acc: 0.5822\n",
            "Epoch 5/15\n",
            "623/625 [============================>.] - ETA: 0s - loss: 0.1006 - acc: 0.9644\n",
            "Epoch 5: val_acc did not improve from 0.67380\n",
            "625/625 [==============================] - 7s 12ms/step - loss: 0.1006 - acc: 0.9645 - val_loss: 3.1772 - val_acc: 0.5894\n",
            "Epoch 6/15\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.0719 - acc: 0.9742\n",
            "Epoch 6: val_acc did not improve from 0.67380\n",
            "625/625 [==============================] - 7s 12ms/step - loss: 0.0721 - acc: 0.9741 - val_loss: 3.4375 - val_acc: 0.5694\n",
            "Epoch 6: early stopping\n",
            "Epoch 1/15\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.0428 - acc: 0.9853\n",
            "Epoch 1: val_acc did not improve from 0.67380\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.0428 - acc: 0.9853 - val_loss: 3.9744 - val_acc: 0.5820\n",
            "Epoch 2/15\n",
            "310/313 [============================>.] - ETA: 0s - loss: 0.0307 - acc: 0.9892\n",
            "Epoch 2: val_acc did not improve from 0.67380\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.0305 - acc: 0.9892 - val_loss: 4.3740 - val_acc: 0.5774\n",
            "Epoch 3/15\n",
            "312/313 [============================>.] - ETA: 0s - loss: 0.0231 - acc: 0.9922\n",
            "Epoch 3: val_acc did not improve from 0.67380\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.0230 - acc: 0.9922 - val_loss: 4.7033 - val_acc: 0.5590\n",
            "Epoch 4/15\n",
            "309/313 [============================>.] - ETA: 0s - loss: 0.0186 - acc: 0.9940\n",
            "Epoch 4: val_acc did not improve from 0.67380\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.0185 - acc: 0.9940 - val_loss: 4.7385 - val_acc: 0.5768\n",
            "Epoch 5/15\n",
            "311/313 [============================>.] - ETA: 0s - loss: 0.0170 - acc: 0.9950\n",
            "Epoch 5: val_acc did not improve from 0.67380\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.0171 - acc: 0.9949 - val_loss: 5.1530 - val_acc: 0.5682\n",
            "Epoch 6/15\n",
            "310/313 [============================>.] - ETA: 0s - loss: 0.0167 - acc: 0.9955\n",
            "Epoch 6: val_acc did not improve from 0.67380\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.0166 - acc: 0.9954 - val_loss: 5.2718 - val_acc: 0.5818\n",
            "Epoch 6: early stopping\n",
            "Epoch 1/15\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 0.9416 - acc: 0.6123\n",
            "Epoch 1: val_acc improved from -inf to 0.65260, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 15s 11ms/step - loss: 0.9416 - acc: 0.6121 - val_loss: 0.8711 - val_acc: 0.6526\n",
            "Epoch 2/15\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.8170 - acc: 0.6581\n",
            "Epoch 2: val_acc improved from 0.65260 to 0.67080, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 13s 11ms/step - loss: 0.8170 - acc: 0.6581 - val_loss: 0.8040 - val_acc: 0.6708\n",
            "Epoch 3/15\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.7574 - acc: 0.6865\n",
            "Epoch 3: val_acc did not improve from 0.67080\n",
            "1250/1250 [==============================] - 13s 10ms/step - loss: 0.7576 - acc: 0.6865 - val_loss: 0.8584 - val_acc: 0.6586\n",
            "Epoch 4/15\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.7083 - acc: 0.7116\n",
            "Epoch 4: val_acc did not improve from 0.67080\n",
            "1250/1250 [==============================] - 13s 10ms/step - loss: 0.7085 - acc: 0.7114 - val_loss: 0.8306 - val_acc: 0.6622\n",
            "Epoch 5/15\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.6655 - acc: 0.7378\n",
            "Epoch 5: val_acc did not improve from 0.67080\n",
            "1250/1250 [==============================] - 13s 10ms/step - loss: 0.6665 - acc: 0.7378 - val_loss: 0.8880 - val_acc: 0.6650\n",
            "Epoch 6/15\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 0.6080 - acc: 0.7654\n",
            "Epoch 6: val_acc did not improve from 0.67080\n",
            "1250/1250 [==============================] - 13s 10ms/step - loss: 0.6083 - acc: 0.7653 - val_loss: 0.9149 - val_acc: 0.6418\n",
            "Epoch 7/15\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.5475 - acc: 0.7898\n",
            "Epoch 7: val_acc did not improve from 0.67080\n",
            "1250/1250 [==============================] - 12s 10ms/step - loss: 0.5475 - acc: 0.7898 - val_loss: 1.0337 - val_acc: 0.6398\n",
            "Epoch 7: early stopping\n",
            "Epoch 1/15\n",
            "623/625 [============================>.] - ETA: 0s - loss: 0.4398 - acc: 0.8338\n",
            "Epoch 1: val_acc did not improve from 0.67080\n",
            "625/625 [==============================] - 7s 12ms/step - loss: 0.4401 - acc: 0.8337 - val_loss: 1.1634 - val_acc: 0.6364\n",
            "Epoch 2/15\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.3516 - acc: 0.8674\n",
            "Epoch 2: val_acc did not improve from 0.67080\n",
            "625/625 [==============================] - 7s 12ms/step - loss: 0.3520 - acc: 0.8673 - val_loss: 1.6003 - val_acc: 0.5942\n",
            "Epoch 3/15\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.2710 - acc: 0.8978\n",
            "Epoch 3: val_acc did not improve from 0.67080\n",
            "625/625 [==============================] - 7s 12ms/step - loss: 0.2710 - acc: 0.8978 - val_loss: 1.8921 - val_acc: 0.6110\n",
            "Epoch 4/15\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.2077 - acc: 0.9209\n",
            "Epoch 4: val_acc did not improve from 0.67080\n",
            "625/625 [==============================] - 7s 12ms/step - loss: 0.2077 - acc: 0.9209 - val_loss: 1.9860 - val_acc: 0.6052\n",
            "Epoch 5/15\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.1498 - acc: 0.9434\n",
            "Epoch 5: val_acc did not improve from 0.67080\n",
            "625/625 [==============================] - 7s 12ms/step - loss: 0.1497 - acc: 0.9435 - val_loss: 2.7496 - val_acc: 0.5800\n",
            "Epoch 6/15\n",
            "621/625 [============================>.] - ETA: 0s - loss: 0.1070 - acc: 0.9608\n",
            "Epoch 6: val_acc did not improve from 0.67080\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.1074 - acc: 0.9606 - val_loss: 3.3469 - val_acc: 0.5546\n",
            "Epoch 6: early stopping\n",
            "Epoch 1/15\n",
            "310/313 [============================>.] - ETA: 0s - loss: 0.0603 - acc: 0.9781\n",
            "Epoch 1: val_acc did not improve from 0.67080\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.0606 - acc: 0.9781 - val_loss: 3.7436 - val_acc: 0.5702\n",
            "Epoch 2/15\n",
            "312/313 [============================>.] - ETA: 0s - loss: 0.0415 - acc: 0.9855\n",
            "Epoch 2: val_acc did not improve from 0.67080\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.0414 - acc: 0.9855 - val_loss: 4.2014 - val_acc: 0.5692\n",
            "Epoch 3/15\n",
            "312/313 [============================>.] - ETA: 0s - loss: 0.0314 - acc: 0.9896\n",
            "Epoch 3: val_acc did not improve from 0.67080\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.0314 - acc: 0.9896 - val_loss: 4.8775 - val_acc: 0.5446\n",
            "Epoch 4/15\n",
            "311/313 [============================>.] - ETA: 0s - loss: 0.0244 - acc: 0.9916\n",
            "Epoch 4: val_acc did not improve from 0.67080\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.0244 - acc: 0.9916 - val_loss: 5.1455 - val_acc: 0.5846\n",
            "Epoch 5/15\n",
            "310/313 [============================>.] - ETA: 0s - loss: 0.0202 - acc: 0.9943\n",
            "Epoch 5: val_acc did not improve from 0.67080\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.0201 - acc: 0.9943 - val_loss: 5.0608 - val_acc: 0.5898\n",
            "Epoch 6/15\n",
            "310/313 [============================>.] - ETA: 0s - loss: 0.0197 - acc: 0.9941\n",
            "Epoch 6: val_acc did not improve from 0.67080\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.0196 - acc: 0.9941 - val_loss: 5.1332 - val_acc: 0.5746\n",
            "Epoch 6: early stopping\n",
            "best model is model_num : 10 and the best val_acc score is 0.6772\n",
            "best hidden units, dense layer, batch is 256, 32, 16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 100\n",
        "hidden_units = best_hu\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(vocab_size, embedding_dim))\n",
        "model.add(GRU(hidden_units))\n",
        "model.add(Dense(best_du, activation='relu'))\n",
        "model.add(Dense(4, activation='softmax'))\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
        "mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
        "# model.summary()\n",
        "\n",
        "hist = model.fit(X_train, y_train, epochs=5, callbacks=[es, mc], batch_size=best_batch, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5WTmM-gx6gI",
        "outputId": "807da80a-72d3-4fc6-a316-f58b9f0dcb1a"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.9295 - acc: 0.6140\n",
            "Epoch 1: val_acc improved from -inf to 0.65240, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 13s 8ms/step - loss: 0.9292 - acc: 0.6137 - val_loss: 0.8336 - val_acc: 0.6524\n",
            "Epoch 2/5\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 0.8007 - acc: 0.6627\n",
            "Epoch 2: val_acc improved from 0.65240 to 0.67620, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.8007 - acc: 0.6625 - val_loss: 0.7921 - val_acc: 0.6762\n",
            "Epoch 3/5\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.7422 - acc: 0.6931\n",
            "Epoch 3: val_acc did not improve from 0.67620\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.7422 - acc: 0.6931 - val_loss: 0.7995 - val_acc: 0.6694\n",
            "Epoch 4/5\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 0.6978 - acc: 0.7195\n",
            "Epoch 4: val_acc did not improve from 0.67620\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.6977 - acc: 0.7196 - val_loss: 0.8167 - val_acc: 0.6708\n",
            "Epoch 5/5\n",
            "1243/1250 [============================>.] - ETA: 0s - loss: 0.6508 - acc: 0.7418\n",
            "Epoch 5: val_acc did not improve from 0.67620\n",
            "1250/1250 [==============================] - 12s 9ms/step - loss: 0.6508 - acc: 0.7419 - val_loss: 0.8401 - val_acc: 0.6618\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = load_model('best_model.h5')"
      ],
      "metadata": {
        "id": "QJqA-qAlIEwt"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "QTwyjBTqIGqc",
        "outputId": "11c23ca8-d2b1-461d-a59b-4049e88cb839"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id                                            reviews\n",
              "0   0                                     채소가 약간 시들어 있어요\n",
              "1   1  발톱 두껍고 단단한 분들 써도 소용없어요 이 테이프 물렁거리고 힘이없어서 들어 올리...\n",
              "2   2                           부들부들 좋네요 입어보고 시원하면 또 살게요\n",
              "3   3      이런 1. 8 골드 주라니깐 파란개 오네 회사전화걸어도 받지도 않고 머하자는거임?\n",
              "4   4       검수도 없이 보내구 불량 배송비 5000원 청구하네요 완전별로 별하나도 아까워요"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e3908707-ea33-461e-bd95-fd772b4890e9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>reviews</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>채소가 약간 시들어 있어요</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>발톱 두껍고 단단한 분들 써도 소용없어요 이 테이프 물렁거리고 힘이없어서 들어 올리...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>부들부들 좋네요 입어보고 시원하면 또 살게요</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>이런 1. 8 골드 주라니깐 파란개 오네 회사전화걸어도 받지도 않고 머하자는거임?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>검수도 없이 보내구 불량 배송비 5000원 청구하네요 완전별로 별하나도 아까워요</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e3908707-ea33-461e-bd95-fd772b4890e9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e3908707-ea33-461e-bd95-fd772b4890e9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e3908707-ea33-461e-bd95-fd772b4890e9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def score_predict(new_sentence):\n",
        "  new_sentence = re.sub(r'[^ㄱ-ㅎㅏ-ㅣ가-힣 ]','', new_sentence)\n",
        "  new_sentence = mecab.morphs(new_sentence)\n",
        "  new_sentence = [word for word in new_sentence if not word in stopwords]\n",
        "  encoded = tokenizer.texts_to_sequences([new_sentence])\n",
        "  pad_new = pad_sequences(encoded, maxlen = max_len)\n",
        "\n",
        "  scorebox=loaded_model.predict((pad_new))\n",
        "  maxscore=max(list(scorebox[0]))\n",
        "  scorelist=[1,2,4,5]\n",
        "  # score = float(loaded_model.predict(pad_new))\n",
        "  # star_score = int(score*100)//20+1\n",
        "  for i in range(4):\n",
        "    if scorebox[0][i]==maxscore:\n",
        "      return scorelist[i]"
      ],
      "metadata": {
        "id": "NPNgBm05KCXO"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(score_predict(\"아 정말 좋아요!!\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-dfLxxWdLuL",
        "outputId": "e1b82a61-906a-4d41-b387-be739e61ff5e"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentest= [\"아진짜 좋아\", \"이거 대박\", \"정말 좋긴한데.. 뭔가 아쉬워요\", \"이거 진짜 진짜 너무 너무 별로다 ... 조상님이 울고가겠어요\"]\n",
        "\n",
        "for sen1 in sentest:\n",
        "  print(sen1)\n",
        "  print(\"다음 문장의 예측 별점은 {}점 입니다.\".format(score_predict(sen1)))\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SaMsfcK2fOQN",
        "outputId": "b022e328-7885-45cf-870e-81847a0d8e59"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "아진짜 좋아\n",
            "다음 문장의 예측 별점은 5점 입니다.\n",
            "\n",
            "이거 대박\n",
            "다음 문장의 예측 별점은 5점 입니다.\n",
            "\n",
            "정말 좋긴한데.. 뭔가 아쉬워요\n",
            "다음 문장의 예측 별점은 2점 입니다.\n",
            "\n",
            "이거 진짜 진짜 너무 너무 별로다 ... 조상님이 울고가겠어요\n",
            "다음 문장의 예측 별점은 1점 입니다.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "QXlFII_2fxHw",
        "outputId": "0db9103d-cccb-401d-d878-fe1f826599b8"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id                                            reviews  target  label  \\\n",
              "0   0                                     조아요 처음구입 싸게햇어요       2      0   \n",
              "1   1   생각보다 잘 안돼요 매지 바른지 하루밖에 안됐는데ㅠㅠ 천원가량 주고 사기 너무 아깝네요       1      0   \n",
              "2   2  디자인은괜찮은데 상품이 금이가서 교환했는데 두번째받은상품도 까져있고 안쪽에 금이가져...       2      0   \n",
              "3   3  기전에 이 제품말고 이마트 트레이더스에서만 팔던 프리미엄 제품을 사용했었습니다 샘플...       2      0   \n",
              "4   4                                   튼튼하고 손목을 잘 받쳐주네요       5      1   \n",
              "\n",
              "                                           tokenized  \n",
              "0                          [조아, 요, 처음, 구입, 싸, 햇, 어요]  \n",
              "1  [생각, 보다, 잘, 안, 돼요, 매지, 바른, 하루, 밖에, 안, 됐, 는데, ㅠ...  \n",
              "2  [디자인, 괜찮, 은데, 상품, 금, 서, 교환, 는데, 두, 번, 째, 받, 상품...  \n",
              "3  [기전, 제품, 말, 이마트, 트, 레이더스, 에서, 만, 팔, 던, 프리미엄, 제...  \n",
              "4                             [튼튼, 손목, 잘, 받쳐, 주, 네요]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9a19b29a-c8ce-4ef9-ac9f-e8331d6c5e54\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>reviews</th>\n",
              "      <th>target</th>\n",
              "      <th>label</th>\n",
              "      <th>tokenized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>조아요 처음구입 싸게햇어요</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>[조아, 요, 처음, 구입, 싸, 햇, 어요]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>생각보다 잘 안돼요 매지 바른지 하루밖에 안됐는데ㅠㅠ 천원가량 주고 사기 너무 아깝네요</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>[생각, 보다, 잘, 안, 돼요, 매지, 바른, 하루, 밖에, 안, 됐, 는데, ㅠ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>디자인은괜찮은데 상품이 금이가서 교환했는데 두번째받은상품도 까져있고 안쪽에 금이가져...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>[디자인, 괜찮, 은데, 상품, 금, 서, 교환, 는데, 두, 번, 째, 받, 상품...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>기전에 이 제품말고 이마트 트레이더스에서만 팔던 프리미엄 제품을 사용했었습니다 샘플...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>[기전, 제품, 말, 이마트, 트, 레이더스, 에서, 만, 팔, 던, 프리미엄, 제...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>튼튼하고 손목을 잘 받쳐주네요</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>[튼튼, 손목, 잘, 받쳐, 주, 네요]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9a19b29a-c8ce-4ef9-ac9f-e8331d6c5e54')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9a19b29a-c8ce-4ef9-ac9f-e8331d6c5e54 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9a19b29a-c8ce-4ef9-ac9f-e8331d6c5e54');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score_predict(\"생각보다 잘 안돼요 매지 바른지 하루밖에 안됐는데ㅠㅠ 천원가량 주고 사기 너무 아깝네요\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-kOGAW3f2mg",
        "outputId": "d190cdb7-ef12-4250-db1f-e38ba0e6dd55"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_sen = test_data.reviews\n",
        "\n",
        "pred = []\n",
        "\n",
        "for sentence in test_sen:\n",
        "  pred.append(score_predict(sentence))"
      ],
      "metadata": {
        "id": "oYI1MmHpKbQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "projectname = \"shop\"\n",
        "model = \"GRU\"\n",
        "testnum = \"006\"\n",
        "\n",
        "submit[\"target\"] = pred\n",
        "submit.head() \n",
        "submit.to_csv(\"sub_{}_{}_model_{}.csv\".format(testnum, projectname, model),index=False)"
      ],
      "metadata": {
        "id": "tR2YLFohK50V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submit.head()"
      ],
      "metadata": {
        "id": "try7dypZLLwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submit.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "7o_Qgaps7KBq",
        "outputId": "ce15d8af-4b78-4451-e34a-b12458d6456d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id  target\n",
              "0   0       2\n",
              "1   1       2\n",
              "2   2       5\n",
              "3   3       2\n",
              "4   4       2"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cd17e61c-26fa-45cc-987b-508c6289db55\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cd17e61c-26fa-45cc-987b-508c6289db55')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cd17e61c-26fa-45cc-987b-508c6289db55 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cd17e61c-26fa-45cc-987b-508c6289db55');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submit.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "uIfHLRmRkvBK",
        "outputId": "11fea83f-9866-4b52-8991-830da268c576"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id  target\n",
              "0   0       5\n",
              "1   1       2\n",
              "2   2       5\n",
              "3   3       2\n",
              "4   4       2"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-25e6bdc6-b08b-46c9-94d4-e83d503d0cc7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-25e6bdc6-b08b-46c9-94d4-e83d503d0cc7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-25e6bdc6-b08b-46c9-94d4-e83d503d0cc7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-25e6bdc6-b08b-46c9-94d4-e83d503d0cc7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    }
  ]
}